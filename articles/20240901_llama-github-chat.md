---
title: "Llamaã¨GitHubã§å®Ÿç¾ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªQ&Aæ©Ÿèƒ½"
emoji: "ğŸ“˜"
type: "tech"
topics: ["LlamaIndex", "OpenAI", "Streamlit", "faiss", "GitHub"]
published: true
---

Amazon CodeCatalyst ã‚„ Cursor ã®ã‚ˆã†ãªãƒªãƒã‚¸ãƒˆãƒªã®ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ Q&A ã™ã‚‹ä»•çµ„ã¿ã‚’ä½œã£ã¦ã¿ãŸ

## å‰æ

æœ€ä½é™ã€ä»¥ä¸‹ã¯å¿…è¦(pipreqs ã‚ˆã‚Šå–å¾—)

```bash
pip install openai
pip install streamlit
pip install faiss-cpu
pip install llama-index
pip install llama-index-readers-github
```

## ã‚³ãƒ¼ãƒ‰ä¾‹

ãƒ»LLM: OpenAI
ãƒ»Vector Store: FAISS
ãƒ»ChatBot: Streamlit
ãƒ»Repository: GitHub

```python
import streamlit as st
import openai
import faiss
from llama_index.core import load_index_from_storage, VectorStoreIndex, StorageContext, Settings
from llama_index.llms.openai import OpenAI
from llama_index.readers.github import GithubRepositoryReader, GithubClient
from llama_index.vector_stores.faiss import FaissVectorStore

# OpenAIè¨­å®š
openai.api_key = "" # APIã‚­ãƒ¼
Settings.llm = OpenAI(
    model="gpt-4o-mini",
    temperature=0.1,
    max_tokens=16000,
)
# Vector Storeè¨­å®š
d = 1536
faiss_index = faiss.IndexFlatL2(d)
# GitHubã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
github_token = "" # ãƒˆãƒ¼ã‚¯ãƒ³
github_client = GithubClient(github_token=github_token, verbose=True)
# ã‚¿ã‚¤ãƒˆãƒ«
st.title("GitHub Q&A with Llama")
# GitHubãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±å…¥åŠ›ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key="repo_form"):
    owner = st.text_input("Owner", value="Flupinochan")
    repo = st.text_input("Repository", value="zenn-content")
    branch = st.text_input("Branch", value="master")
    filter_directories_input = st.text_input("EXCLUDE Filter Directories (comma-separated)", value="books,images")
    filter_file_extensions_input = st.text_input("INCLUDE Filter File Extensions (comma-separated)", value=".md,.ts,.tsx,.py")
    submit_button = st.form_submit_button("Submit")
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
if "query_engine" not in st.session_state:
    st.session_state.query_engine = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
# Submitãƒœã‚¿ãƒ³å®Ÿè¡Œæ™‚ã®å‡¦ç†
if submit_button:
    with st.spinner("Initializing index..."):
        try:
            filter_directories = [dir.strip() for dir in filter_directories_input.split(",") if dir.strip()]
            filter_file_extensions = [ext.strip() for ext in filter_file_extensions_input.split(",") if ext.strip()]
            reader = GithubRepositoryReader(
                github_client=github_client,
                owner=owner,
                repo=repo,
                use_parser=True,
                verbose=False,
                filter_directories=(filter_directories, GithubRepositoryReader.FilterType.EXCLUDE),
                filter_file_extensions=(filter_file_extensions, GithubRepositoryReader.FilterType.INCLUDE),
                concurrent_requests=5,
                retries=5,
                timeout=300,
            )
            documents = reader.load_data(branch=branch) # GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’èª­ã¿è¾¼ã‚€
            vector_store = FaissVectorStore(faiss_index=faiss_index)
            storage_context = StorageContext.from_defaults(vector_store=vector_store)
            index = VectorStoreIndex.from_documents(documents, storage_context=storage_context) # Vectorã«ä¿å­˜/Indexä½œæˆ
            index.storage_context.persist()
            vector_store = FaissVectorStore.from_persist_dir("./storage")
            storage_context = StorageContext.from_defaults(vector_store=vector_store, persist_dir="./storage") # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªstorageã«æ°¸ä¹…ä¿å­˜
            st.session_state.query_engine = load_index_from_storage(storage_context=storage_context).as_query_engine(streaming=True, similarity_top_k=1)
            st.success("Index initialized successfully.")
        except Exception as e:
            st.error(f"An error occurred: {e}")

# ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å…¥åŠ›æ¬„ã¨é€ä¿¡ãƒœã‚¿ãƒ³
user_message = st.text_input("Enter your message:")
if st.button("Send"):
    if user_message:
        if st.session_state.query_engine:
            with st.spinner("Processing your message..."):
                try:
                    instruction = "ä»¥ä¸‹ã®å†…å®¹ã«ã¤ã„ã¦ã€é•·æ–‡ã§è‰¯ã„ã®ã§è©³ç´°ã‹ã¤ä¸å¯§ã«æœ€ä½ã§ã‚‚2000å­—ä»¥ä¸Šã§Markdownå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                    final_prompt = f"{instruction}\n{user_message}"
                    streaming_response = st.session_state.query_engine.query(final_prompt) # è³ªå•å®Ÿè¡Œ
                    placeholder = st.empty()
                    chat_history = st.session_state.get("chat_history", [])
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã®å‡¦ç†
                    full_text = ""
                    for text in streaming_response.response_gen:
                        full_text += text
                        placeholder.write(full_text)
                    chat_history.append(full_text)
                    st.session_state.chat_history = chat_history
                except Exception as e:
                    st.error(f"An error occurred while querying: {e}")
        else:
            st.write("Please submit the form to initialize the index.")
    else:
        st.write("Please enter a message.")
```

## å®Ÿè¡Œä¾‹

æŒ‡å®šã—ãŸ GitHub ãƒªãƒã‚¸ãƒˆãƒªã‚’èª­ã¿è¾¼ã‚€
![](/images/20240901_llama-github-chat/llama-github-chat1.gif)
è³ªå•ã™ã‚‹
![](/images/20240901_llama-github-chat/llama-github-chat2.gif)
<br>
<br>
P.S. GitHub REST API ã§ä¸€è¦§å–å¾—ã™ã‚‹æ–¹æ³•ã¨å¤§å·®ãªã‹ã£ãŸâ€¦
